from flask import Flask, request, jsonify, Response
import google.generativeai as genai
import os
from dotenv import load_dotenv
import time
from collections import OrderedDict
import faiss
import pickle
import numpy as np

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

app = Flask(__name__)

# --- C·∫§U H√åNH T·ªêI ∆ØU ---

# 1. B·ªô nh·ªõ ƒë·ªám (Cache) ƒë·ªÉ l∆∞u c√°c c√¢u tr·∫£ l·ªùi ƒë√£ c√≥
# D√πng OrderedDict ƒë·ªÉ d·ªÖ d√†ng qu·∫£n l√Ω v√† x√≥a entry c≈© nh·∫•t (LRU Cache)
response_cache = OrderedDict()
CACHE_MAX_SIZE = 100

# 2. Rate Limiting ƒë·ªÉ ch·ªëng spam
request_history = {}
RATE_LIMIT = 15  # S·ªë request t·ªëi ƒëa
WINDOW_MS = 60 * 1000  # Trong 1 ph√∫t (60,000 ms)

# 3. L·∫•y danh s√°ch API keys, cho ph√©p xoay v√≤ng n·∫øu 1 key b·ªã l·ªói
# Vercel s·∫Ω ƒë·ªçc bi·∫øn m√¥i tr∆∞·ªùng n√†y. ·ªû local, n√≥ s·∫Ω ƒë·ªçc t·ª´ file .env
GEMINI_API_KEYS = [key.strip() for key in (os.getenv("GEMINI_API_KEY") or "").split(',') if key.strip()]

# --- 4. T·∫¢I DATABASE VECTOR (FAISS) ---
try:
    # Vercel s·∫Ω copy c√°c file n√†y v√†o /var/task/ khi build
    # C·∫ßn ƒë·∫£m b·∫£o c√°c file n√†y n·∫±m ·ªü th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
    current_dir = os.path.dirname(os.path.abspath(__file__))
    index_path = os.path.join(current_dir, '..', 'luat_vn.index')
    pkl_path = os.path.join(current_dir, '..', 'luat_vn.pkl')
    
    faiss_index = faiss.read_index(index_path)
    with open(pkl_path, "rb") as f:
        faiss_documents = pickle.load(f)
    print("‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng FAISS index v√† documents.")
except Exception as e:
    faiss_index = None
    faiss_documents = None
    print(f"‚ö†Ô∏è L·ªói khi t·∫£i FAISS index: {e}. Ch·ª©c nƒÉng t√¨m ki·∫øm lu·∫≠t s·∫Ω b·ªã ·∫£nh h∆∞·ªüng.")

# --- K·∫æT TH√öC C·∫§U H√åNH ---

# --- C√ÅC H√ÄM H·ªñ TR·ª¢ ---

def search_faiss(query, k=5, score_threshold=0.6):
    """T√¨m ki·∫øm trong DB vector c·ª•c b·ªô v·ªõi FAISS."""
    if not faiss_index or not faiss_documents or not GOOGLE_KEYS:
        return None
    try:
        genai.configure(api_key=GEMINI_API_KEYS[0])
        result = genai.embed_content(model="models/text-embedding-004", content=query, task_type="retrieval_query")
        q_embed = np.array([result['embedding']]).astype('float32')
        faiss.normalize_L2(q_embed)
        
        scores, indices = faiss_index.search(q_embed, k)
        
        relevant_docs = []
        if len(scores) > 0 and len(indices) > 0:
            for i, score in enumerate(scores[0]):
                if score >= score_threshold:
                    relevant_docs.append(faiss_documents[indices[0][i]])
        
        if relevant_docs:
            return "\n---\n".join(relevant_docs)
    except Exception as e:
        print(f"L·ªói khi t√¨m ki·∫øm FAISS: {e}")
    return None

def classify_intent(text):
    """Ph√¢n lo·∫°i √Ω ƒë·ªãnh: True (X√£ giao), False (H·ªèi lu·∫≠t)."""
    text_lower = text.lower().strip()
    word_count = len(text_lower.split())
    social_keywords = ["hi", "hello", "ch√†o", "c·∫£m ∆°n", "b·∫°n l√† ai", "t·∫°m bi·ªát", "t√™n g√¨", "kh·ªèe kh√¥ng"]
    traffic_keywords = ["lu·∫≠t", "ph·∫°t", "bi·ªÉn b√°o", "t·ªëc ƒë·ªô", "n·ªìng ƒë·ªô c·ªìn", "xe m√°y", "√¥ t√¥", "ƒë√®n ƒë·ªè"]
    
    if any(k in text_lower for k in traffic_keywords): return False
    if any(k in text_lower for k in social_keywords) and word_count < 6: return True
    if word_count > 15: return False # C√¢u d√†i th∆∞·ªùng l√† h·ªèi nghi√™m t√∫c
    return True # M·∫∑c ƒë·ªãnh c√¢u ng·∫Øn l√† x√£ giao

# H√†m x·ª≠ l√Ω CORS
@app.after_request
def after_request(response):
    header = response.headers
    header['Access-Control-Allow-Origin'] = '*'
    header['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    header['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
    return response


@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def handle_chat():
    if request.method == 'OPTIONS':
        return '', 204

    # --- KI·ªÇM TRA RATE LIMIT ---
    ip = request.headers.get('x-forwarded-for', request.remote_addr)
    now = int(time.time() * 1000)
    user_requests = request_history.get(ip, [])
    
    # L·ªçc ra c√°c request trong kho·∫£ng th·ªùi gian WINDOW_MS
    recent_requests = [t for t in user_requests if now - t < WINDOW_MS]
    
    if len(recent_requests) >= RATE_LIMIT:
        return jsonify({"error": "B·∫°n ƒëang h·ªèi qu√° nhanh, vui l√≤ng th·ª≠ l·∫°i sau gi√¢y l√°t."}), 429
    
    recent_requests.append(now)
    request_history[ip] = recent_requests
    
    # --- X·ª¨ L√ù REQUEST ---
    if not GEMINI_API_KEYS:
        return jsonify({"error": "API Key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh tr√™n server."}), 500

    try:
        data = request.get_json()
        user_prompt = data.get('prompt')
        history = data.get('history', [])

        if not user_prompt:
            return jsonify({"error": "Kh√¥ng c√≥ prompt n√†o ƒë∆∞·ª£c cung c·∫•p."}), 400

        clean_prompt = user_prompt.strip().lower()

        # --- KI·ªÇM TRA CACHE ---
        if clean_prompt in response_cache:
            print(f"‚ö°Ô∏è Cache Hit cho IP: {ip}")
            response_cache.move_to_end(clean_prompt)
            def generate_cached():
                yield response_cache[clean_prompt]
            return Response(generate_cached(), mimetype='text/plain; charset=utf-8')

        print(f"‚ö†Ô∏è Cache Miss. G·ªçi API cho IP: {ip}")

        # --- PH√ÇN LO·∫†I & T√åM KI·∫æM ---
        is_social = classify_intent(user_prompt)
        if not is_social:
            context = search_faiss(user_prompt) or "Kh√¥ng t√¨m th·∫•y th√¥ng tin trong c∆° s·ªü d·ªØ li·ªáu lu·∫≠t."
            system_prompt = f"""
            B·∫°n l√† Tr·ª£ l√Ω Giao th√¥ng 2025, m·ªôt chuy√™n gia lu·∫≠t. D·ª±a v√†o D·ªÆ LI·ªÜU THAM KH·∫¢O v√† L·ªäCH S·ª¨ CHAT ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
            QUY T·∫ÆC:
            1. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, S√öC T√çCH, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
            2. D√πng ICON (‚úÖ, ‚õî, ‚ö†Ô∏è, üí°...) ƒë·∫ßu d√≤ng cho sinh ƒë·ªông.
            3. N·∫øu c√≥ m·ª©c ph·∫°t, h√£y n√™u r√µ theo Nƒê 168/2024.
            4. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y n√≥i "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c v·ªÅ v·∫•n ƒë·ªÅ n√†y".
            5. KH√îNG s·ª≠ d·ª•ng d·∫•u ** ƒë·ªÉ in ƒë·∫≠m.
            ---
            D·ªÆ LI·ªÜU THAM KH·∫¢O: {context}
            """
        else:
            system_prompt = "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI vui t√≠nh, h√†i h∆∞·ªõc, tr·∫ª trung (Gen Z). H√£y tr·∫£ l·ªùi ng∆∞·ªùi d√πng m·ªôt c√°ch th√¢n thi·ªán, ng·∫Øn g·ªçn v√† 't∆∞ng t·ª≠ng' d·ªÖ th∆∞∆°ng. ƒê·ª´ng qu√° nghi√™m t√∫c."

        conversation_history = "\n".join([f'{msg["role"]}: {msg["text"]}' for msg in history[-5:]])
        full_prompt = f"{system_prompt}\n\nL·ªäCH S·ª¨ CHAT:\n{conversation_history}\n\nC√¢u h·ªèi m·ªõi: \"{user_prompt}\""

        def generate_stream():
            full_response_text = ""
            for api_key in GEMINI_API_KEYS:
                try:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel(model_name="gemini-1.5-flash-latest")
                    stream = model.generate_content(full_prompt, stream=True)
                    for chunk in stream:
                        if chunk.text:
                            full_response_text += chunk.text
                            yield chunk.text
                    
                    response_cache[clean_prompt] = full_response_text
                    if len(response_cache) > CACHE_MAX_SIZE:
                        response_cache.popitem(last=False)
                    return
                except Exception as e:
                    print(f"L·ªói v·ªõi API key: {e}")
                    continue
            yield "Xin l·ªói, h·ªá th·ªëng ƒëang b·∫≠n ho·∫∑c g·∫∑p s·ª± c·ªë k·∫øt n·ªëi. Vui l√≤ng th·ª≠ l·∫°i sau."

        return Response(generate_stream(), mimetype='text/plain; charset=utf-8')

    except Exception as e:
        error_message = str(e)
        print(f"L·ªói nghi√™m tr·ªçng: {error_message}")
        # X·ª≠ l√Ω l·ªói c·ª• th·ªÉ t·ª´ Google AI
        if "API_KEY_INVALID" in error_message:
             return jsonify({"error": "M·ªôt ho·∫∑c nhi·ªÅu API Key kh√¥ng h·ª£p l·ªá."}), 500
        if "rate limit" in error_message.lower():
             return jsonify({"error": "API c·ªßa Google ƒëang b·ªã qu√° t·∫£i, vui l√≤ng th·ª≠ l·∫°i sau."}), 429
        
        return jsonify({"error": "L·ªói m√°y ch·ªß n·ªôi b·ªô, kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu."}), 500
